{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning deep neural networks Ôºç MobileFaceNet\n",
    "\n",
    "Prunning MobileFaceNet could be a little tricky. The detailed structure of the model architecture is shown as below. The MobileFaceNet consists of three types of block -- Conv_block, Delpth_wise module and Residual bottleneck. The residual bottleneck with shortcuts (similar to resnet) are used as main building blocks. The Depth-wise module firstly applies 1x1 conv layer with output channels specificed by the expansion factor, then the depthwise and pointwise convolution layers are utilized to reduce computation cost. The residual block is a stack of depth-wise modules with shortcuts applied. \n",
    "\n",
    "<img src=\"imgs/8.png\"  width=\"600\" style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileFaceNet(\n",
       "  (conv1): Conv_block(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (prelu): PReLU(num_parameters=64)\n",
       "  )\n",
       "  (conv2_dw): Conv_block(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (prelu): PReLU(num_parameters=64)\n",
       "  )\n",
       "  (conv_23): Depth_Wise(\n",
       "    (conv): Conv_block(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (conv_dw): Conv_block(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (project): Linear_block(\n",
       "      (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_3): Residual(\n",
       "    (model): Sequential(\n",
       "      (0): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_34): Depth_Wise(\n",
       "    (conv): Conv_block(\n",
       "      (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "    )\n",
       "    (conv_dw): Conv_block(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "    )\n",
       "    (project): Linear_block(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_4): Residual(\n",
       "    (model): Sequential(\n",
       "      (0): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_45): Depth_Wise(\n",
       "    (conv): Conv_block(\n",
       "      (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=512)\n",
       "    )\n",
       "    (conv_dw): Conv_block(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=512)\n",
       "    )\n",
       "    (project): Linear_block(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_5): Residual(\n",
       "    (model): Sequential(\n",
       "      (0): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_6_sep): Conv_block(\n",
       "    (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (prelu): PReLU(num_parameters=512)\n",
       "  )\n",
       "  (conv_6_dw): Linear_block(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), groups=512, bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_6_flatten): Flatten()\n",
       "  (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "  (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MFN.Base_Model.face_model import *\n",
    "\n",
    "model = MobileFaceNet(512)\n",
    "model.load_state_dict(torch.load('MFN/Base_Model/MobileFace_Net', map_location=lambda storage, loc: storage))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prunning the depth_wise module \n",
    "\n",
    "Let's look at the depth_wise module prunning. The depth_wise module consists three convolutional layers. The first 1x1 conv layer is used as a bottleneck. The second depth wise conv has the filters equivalent to \"in_channels\" and thus each input channel is convolved with its own set of filter. The output feature map size depends on the stride applied from depth_wise conv. The third 1x1 linear conv, also called point-wise conv, is appled to give the desired output channels. For this case, we are able to **only** prune the first 1x1 convolutional layer. The second depth-wise conv needs to prune the same filter indexs since the output's number of channels of 1x1 conv should be the same as the number of depth-wise conv filters. Since the output of depth-wise conv is shrinked. The third liner filter in-channels will need to be reconstructed. The below diagram illustrates the depth_wise module prunning approach.\n",
    "\n",
    "<img src=\"imgs/6.png\"  width=\"800\" style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prunning the residual bottleneck \n",
    "\n",
    "The residual bottlenecks are stack of depth-wise module with short-cut connection. In this scenario, each output from depth-wise module should have the same shape since we apply element-wise addition. Therefore, the output feature map of the whole residual bottleneck is the target that we want to prune. Once we decide which **linear conv** channel to be prunned based on the ranking of whole residual bottleneck output, each depth-wise module lincear conv and the upperstream conv's \"out_channels\" will need to be pruned to maintain the shape. The implication is that if a certain channel of the feature map which is the sum of all depth-wise module output is trivial to the loss, that means each element is trivial. Imagine it for a moment, but hey don't forget to shrink the next conv layer \"in_channels\" \n",
    "\n",
    "<img src=\"imgs/7.png\"  width=\"800\" style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All right ! Hope you understand the basics on MobileFaceNet prunning. Let's look into the detailed code. \n",
    "\n",
    "At first, let's rearrange the model to an ordered module list to make it eaiser for indexing and subsequent prunning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: Conv_block(\n",
       "   (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=64)\n",
       " ), 1: Conv_block(\n",
       "   (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "   (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=64)\n",
       " ), 2: Conv_block(\n",
       "   (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=128)\n",
       " ), 3: Conv_block(\n",
       "   (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=128)\n",
       " ), 4: Linear_block(\n",
       "   (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 5: Conv_block(\n",
       "   (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=128)\n",
       " ), 6: Conv_block(\n",
       "   (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=128)\n",
       " ), 7: Linear_block(\n",
       "   (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 8: Conv_block(\n",
       "   (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=128)\n",
       " ), 9: Conv_block(\n",
       "   (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=128)\n",
       " ), 10: Linear_block(\n",
       "   (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 11: Conv_block(\n",
       "   (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=128)\n",
       " ), 12: Conv_block(\n",
       "   (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=128)\n",
       " ), 13: Linear_block(\n",
       "   (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 14: Conv_block(\n",
       "   (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=128)\n",
       " ), 15: Conv_block(\n",
       "   (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=128)\n",
       " ), 16: Linear_block(\n",
       "   (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 17: Conv_block(\n",
       "   (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 18: Conv_block(\n",
       "   (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 19: Linear_block(\n",
       "   (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 20: Conv_block(\n",
       "   (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 21: Conv_block(\n",
       "   (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 22: Linear_block(\n",
       "   (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 23: Conv_block(\n",
       "   (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 24: Conv_block(\n",
       "   (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 25: Linear_block(\n",
       "   (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 26: Conv_block(\n",
       "   (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 27: Conv_block(\n",
       "   (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 28: Linear_block(\n",
       "   (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 29: Conv_block(\n",
       "   (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 30: Conv_block(\n",
       "   (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 31: Linear_block(\n",
       "   (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 32: Conv_block(\n",
       "   (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 33: Conv_block(\n",
       "   (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 34: Linear_block(\n",
       "   (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 35: Conv_block(\n",
       "   (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 36: Conv_block(\n",
       "   (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 37: Linear_block(\n",
       "   (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 38: Conv_block(\n",
       "   (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=512)\n",
       " ), 39: Conv_block(\n",
       "   (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "   (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=512)\n",
       " ), 40: Linear_block(\n",
       "   (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 41: Conv_block(\n",
       "   (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 42: Conv_block(\n",
       "   (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 43: Linear_block(\n",
       "   (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 44: Conv_block(\n",
       "   (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 45: Conv_block(\n",
       "   (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "   (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=256)\n",
       " ), 46: Linear_block(\n",
       "   (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 47: Conv_block(\n",
       "   (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "   (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (prelu): PReLU(num_parameters=512)\n",
       " ), 48: Linear_block(\n",
       "   (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), groups=512, bias=False)\n",
       "   (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       " ), 49: Flatten(), 50: Linear(in_features=512, out_features=512, bias=False), 51: BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = 0\n",
    "modules = {}\n",
    "for names, module in list(model._modules.items()):\n",
    "    if isinstance(module, Depth_Wise):\n",
    "        for _, module_sub in list(module._modules.items()):\n",
    "            modules[index] = module_sub\n",
    "            index += 1\n",
    "\n",
    "    elif isinstance(module, Residual):\n",
    "        for i in range(len(module.model)):\n",
    "            for _, model_sub_sub in list(module.model[i]._modules.items()):\n",
    "                modules[index] = model_sub_sub\n",
    "                index += 1          \n",
    "    else:\n",
    "        modules[index] = module\n",
    "        index += 1\n",
    "modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import some prunning functions which return new constructed layers based on the to-be-pruned filters. The approaches have been explained on \"Prunning MTCNN Tutorial\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MFN.utils.prune_MFN import prune_Conv2d, prune_BN, prune_PReLu, prune_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a MobileFaceNet prunning function as shown below. The \"prune_MFN\" function will accept the layer_index and filter_index as a tuple, return a pruned model. \n",
    "\n",
    "1. if the layer_index represents the Conv block or first 1x1 conv layer in depth_wise module, a while loop will be performed until the next layer is not depth-wise conv layer, the next layer may be a conv layer or fully connected (i.e. layer_index = 47). both cases need to be taken care.\n",
    "2. if the layer_index is the one which gives the output of whole bottleneck block (i.e. 16, 37, 46), each depth-wise module linear conv will need to be pruned, as well as the upperstream \"out_channels\" and downstream conv layer \"in_channels\" for sure.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_MFN(model, layer_index, *filter_index, use_cuda=True):\n",
    "    \n",
    "    # regroup the model modules \n",
    "    index = 0\n",
    "    modules = {}\n",
    "    for names, module in list(model._modules.items()):\n",
    "        if isinstance(module, Depth_Wise):\n",
    "            for _, module_sub in list(module._modules.items()):\n",
    "                modules[index] = module_sub\n",
    "                index += 1\n",
    "                \n",
    "        elif isinstance(module, Residual):\n",
    "            for i in range(len(module.model)):\n",
    "                for _, model_sub_sub in list(module.model[i]._modules.items()):\n",
    "                    modules[index] = model_sub_sub\n",
    "                    index += 1          \n",
    "        else:\n",
    "            modules[index] = module\n",
    "            index += 1\n",
    "\n",
    "    if layer_index == None or filter_index == []:\n",
    "        return model, modules\n",
    "            \n",
    "    if isinstance(modules[layer_index], Conv_block):\n",
    "        if modules[layer_index].conv.groups != modules[layer_index].conv.in_channels:\n",
    "        \n",
    "            conv = modules[layer_index].conv\n",
    "            bn = modules[layer_index].bn\n",
    "            prelu = modules[layer_index].prelu\n",
    "            \n",
    "            modules[layer_index].conv = prune_Conv2d(conv, filter_index, Next=False, use_cuda = use_cuda)\n",
    "            modules[layer_index].bn = prune_BN(bn, filter_index, use_cuda = use_cuda)\n",
    "            modules[layer_index].prelu = prune_PReLu(prelu, filter_index, use_cuda = use_cuda)\n",
    "            \n",
    "            next_conv = modules[layer_index+1].conv\n",
    "            modules[layer_index+1].conv = prune_Conv2d(next_conv, filter_index, Next=True, use_cuda = use_cuda)\n",
    "            while modules[layer_index+1].conv.groups != 1:\n",
    "                bn = modules[layer_index+1].bn\n",
    "                modules[layer_index+1].bn = prune_BN(bn, filter_index, use_cuda = use_cuda)\n",
    "                if isinstance(modules[layer_index+1], Conv_block):\n",
    "                    prelu = modules[layer_index+1].prelu\n",
    "                    modules[layer_index+1].prelu = prune_PReLu(prelu, filter_index, use_cuda = use_cuda)\n",
    "                layer_index += 1\n",
    "                if isinstance(modules[layer_index+2], Linear):\n",
    "                    next_linear = modules[layer_index+2]\n",
    "                    modules[layer_index+2] = prune_linear(next_linear, next_conv, filter_index, use_cuda = use_cuda)\n",
    "                else:\n",
    "                    next_conv = modules[layer_index+1].conv\n",
    "                    modules[layer_index+1].conv = prune_Conv2d(next_conv, filter_index, Next=True, use_cuda = use_cuda)\n",
    "                if isinstance(modules[layer_index+1], Flatten):\n",
    "                    break\n",
    "    \n",
    "    if layer_index == 16:\n",
    "        \n",
    "        num_blocks = 4\n",
    "        for i in range(num_blocks+1):\n",
    "            conv = modules[layer_index - 3*i].conv\n",
    "            bn = modules[layer_index - 3*i].bn\n",
    "            \n",
    "            modules[layer_index - 3*i].conv = prune_Conv2d(conv, filter_index, Next=False, use_cuda = use_cuda)\n",
    "            modules[layer_index - 3*i].bn = prune_BN(bn, filter_index, use_cuda = use_cuda)\n",
    "            \n",
    "            next_conv = modules[layer_index+1-3*i].conv\n",
    "            modules[layer_index+1-3*i].conv = prune_Conv2d(next_conv, filter_index, Next=True, use_cuda = use_cuda)\n",
    "            \n",
    "    if layer_index == 37:\n",
    "        \n",
    "        num_blocks = 6\n",
    "        for i in range(num_blocks+1):\n",
    "            conv = modules[layer_index - 3*i].conv\n",
    "            bn = modules[layer_index - 3*i].bn\n",
    "            \n",
    "            modules[layer_index - 3*i].conv = prune_Conv2d(conv, filter_index, Next=False, use_cuda = use_cuda)\n",
    "            modules[layer_index - 3*i].bn = prune_BN(bn, filter_index, use_cuda = use_cuda)\n",
    "            \n",
    "            next_conv = modules[layer_index+1-3*i].conv\n",
    "            modules[layer_index+1-3*i].conv = prune_Conv2d(next_conv, filter_index, Next=True, use_cuda = use_cuda)\n",
    "    \n",
    "    if layer_index == 46:\n",
    "        \n",
    "        num_blocks = 2\n",
    "        for i in range(num_blocks+1):\n",
    "            conv = modules[layer_index - 3*i].conv\n",
    "            bn = modules[layer_index - 3*i].bn\n",
    "            \n",
    "            modules[layer_index - 3*i].conv = prune_Conv2d(conv, filter_index, Next=False, use_cuda = use_cuda)\n",
    "            modules[layer_index - 3*i].bn = prune_BN(bn, filter_index, use_cuda = use_cuda)\n",
    "            \n",
    "            next_conv = modules[layer_index+1-3*i].conv\n",
    "            modules[layer_index+1-3*i].conv = prune_Conv2d(next_conv, filter_index, Next=True, use_cuda = use_cuda)\n",
    "             \n",
    "    index = 0\n",
    "    for names, module in list(model._modules.items()):\n",
    "        if isinstance(module, Depth_Wise):\n",
    "            for _, module_sub in list(module._modules.items()):\n",
    "                module_sub = modules[index]\n",
    "                index += 1\n",
    "                \n",
    "        elif isinstance(module, Residual):\n",
    "            for i in range(len(module.model)):\n",
    "                for _, model_sub_sub in list(module.model[i]._modules.items()):\n",
    "                    model_sub_sub = modules[index]\n",
    "                    index += 1          \n",
    "        else:\n",
    "            model._modules[names] = modules[index]\n",
    "            index += 1\n",
    "    \n",
    "    return model, modules\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example, you can play with the layer_index and filters_index as you want. But note that not all the layer index is valid. The layer index acceptable by the \"prune_MFN\" function includes:  \n",
    " \n",
    "1. conv_block\n",
    "2. first 1x1 conv layer in depth_wise module \n",
    "3. the linear conv layer which gives the output of whole bottleneck block. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileFaceNet(\n",
       "  (conv1): Conv_block(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (prelu): PReLU(num_parameters=64)\n",
       "  )\n",
       "  (conv2_dw): Conv_block(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (prelu): PReLU(num_parameters=64)\n",
       "  )\n",
       "  (conv_23): Depth_Wise(\n",
       "    (conv): Conv_block(\n",
       "      (conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (conv_dw): Conv_block(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=128)\n",
       "    )\n",
       "    (project): Linear_block(\n",
       "      (conv): Conv2d(128, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_3): Residual(\n",
       "    (model): Sequential(\n",
       "      (0): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(62, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(128, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(62, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(128, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(62, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(128, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(62, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=128)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(128, 62, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(62, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_34): Depth_Wise(\n",
       "    (conv): Conv_block(\n",
       "      (conv): Conv2d(62, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "    )\n",
       "    (conv_dw): Conv_block(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=256)\n",
       "    )\n",
       "    (project): Linear_block(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_4): Residual(\n",
       "    (model): Sequential(\n",
       "      (0): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (2): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (4): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (5): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_45): Depth_Wise(\n",
       "    (conv): Conv_block(\n",
       "      (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=512)\n",
       "    )\n",
       "    (conv_dw): Conv_block(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
       "      (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (prelu): PReLU(num_parameters=512)\n",
       "    )\n",
       "    (project): Linear_block(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv_5): Residual(\n",
       "    (model): Sequential(\n",
       "      (0): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Depth_Wise(\n",
       "        (conv): Conv_block(\n",
       "          (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (conv_dw): Conv_block(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (prelu): PReLU(num_parameters=256)\n",
       "        )\n",
       "        (project): Linear_block(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_6_sep): Conv_block(\n",
       "    (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (prelu): PReLU(num_parameters=512)\n",
       "  )\n",
       "  (conv_6_dw): Linear_block(\n",
       "    (conv): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), groups=512, bias=False)\n",
       "    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv_6_flatten): Flatten()\n",
       "  (linear): Linear(in_features=512, out_features=512, bias=False)\n",
       "  (bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_index = 16\n",
    "filter_index = (2,4)\n",
    "\n",
    "model, module = prune_MFN(model, layer_index, *filter_index, use_cuda=False)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FilterPrunner Class\n",
    "\n",
    "The FilterPrunner class becomes quite straightforward. Instead of the model, the \"forward\" function accepts converted module list, iterate each item to capture the intermedia feature maps. The prunning_layers lists all the valid layer index acceptable by \"prune_MFN\" function. If the index belongs to the prunning_layers list. The grad is hooked and the taylor value is calculated. All other functions are the same as MTCNN prunning.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterPrunner:\n",
    "    def __init__(self, model, use_cuda = False):\n",
    "        self.model = model\n",
    "        self.reset()\n",
    "        self.use_cuda = use_cuda\n",
    "\n",
    "    def reset(self):\n",
    "        self.filter_ranks = {}\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.activations = []\n",
    "        self.gradients = []\n",
    "        self.grad_index = 0\n",
    "        self.activation_to_layer = {}\n",
    "\n",
    "        activation_index = 0\n",
    "        Res_layers = (7, 10, 13, 16, 22, 25, 28, 31, 34, 37, 43, 46) # res layers requiring shortcuts \n",
    "        prunning_layers = (0, 2, 5, 8, 11, 14, 17, 20, 23, 26, 29, 32, 35, 38, 41, 44, 47, 16, 37, 46) # the layers to be prunned\n",
    "        outputs = {}\n",
    "        for index, module in self.model.items():\n",
    "            if isinstance(module, Linear_block) and index in Res_layers:\n",
    "                x = self.model[index](x) + outputs[index-3]\n",
    "            else:\n",
    "                x = self.model[index](x)\n",
    "                \n",
    "            outputs[index] = x\n",
    "            \n",
    "            if index in prunning_layers:\n",
    "                x.register_hook(self.compute_rank)\n",
    "                self.activations.append(x)\n",
    "                self.activation_to_layer[activation_index] = index # the ith conv2d layer\n",
    "                activation_index += 1\n",
    "\n",
    "        return l2_norm(x)\n",
    "\n",
    "    def compute_rank(self, grad):\n",
    "        activation_index = len(self.activations) - self.grad_index - 1\n",
    "        activation = self.activations[activation_index]\n",
    "        taylor = activation * grad\n",
    "\n",
    "        # Get the average value for every filter,\n",
    "        # accross all the other dimensions\n",
    "        taylor = taylor.mean(dim=(0, 2, 3)).data\n",
    "\n",
    "        if activation_index not in self.filter_ranks:\n",
    "            self.filter_ranks[activation_index] = \\\n",
    "                torch.FloatTensor(activation.size(1)).zero_()\n",
    "\n",
    "            if self.use_cuda:\n",
    "                self.filter_ranks[activation_index] = self.filter_ranks[activation_index].cuda()\n",
    "\n",
    "        self.filter_ranks[activation_index] += taylor\n",
    "        self.grad_index += 1\n",
    "\n",
    "    def lowest_ranking_filters(self, num):\n",
    "        data = []\n",
    "        for i in sorted(self.filter_ranks.keys()):\n",
    "            for j in range(self.filter_ranks[i].size(0)):\n",
    "                data.append((self.activation_to_layer[i], j, self.filter_ranks[i][j]))\n",
    "\n",
    "        return nsmallest(num, data, itemgetter(2))\n",
    "\n",
    "    def normalize_ranks_per_layer(self):\n",
    "        for i in self.filter_ranks:\n",
    "            v = torch.abs(self.filter_ranks[i]).cpu()\n",
    "            v = v / np.sqrt(torch.sum(v * v))\n",
    "            self.filter_ranks[i] = v\n",
    "\n",
    "    def get_prunning_plan(self, num_filters_to_prune):\n",
    "        filters_to_prune = self.lowest_ranking_filters(num_filters_to_prune)\n",
    "                \n",
    "        filters_to_prune_per_layer = {}\n",
    "        for (l, f, _) in filters_to_prune:\n",
    "            if l not in filters_to_prune_per_layer:\n",
    "                filters_to_prune_per_layer[l] = []\n",
    "            filters_to_prune_per_layer[l].append(f)\n",
    "    \n",
    "    \n",
    "        for l in filters_to_prune_per_layer:\n",
    "            filters_to_prune_per_layer[l] = sorted(filters_to_prune_per_layer[l])\n",
    "\n",
    "        return filters_to_prune_per_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a substance of FilterPrunner and demonstrate the prunning process. The Arcface head has to be imported to calcuate the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prunner = FilterPrunner(modules, use_cuda = False) \n",
    "\n",
    "model.train() \n",
    "margin = Arcface(embedding_size=512, classnum=85742,  s=32., m=0.5)\n",
    "checkpoint = torch.load(\"MFN/Base_Model/Iter_528000_margin.ckpt\", map_location=lambda storage, loc: storage)\n",
    "margin.load_state_dict(checkpoint['net_state_dict'])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "prunner.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one fake input image batch and label batch for loss calucuation and backpropagation for grad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(3,3,112,112)\n",
    "label = torch.Tensor([1,5,10]).type(torch.LongTensor)\n",
    "\n",
    "model.zero_grad()\n",
    "    \n",
    "with torch.set_grad_enabled(True):\n",
    "    raw_logits = prunner.forward(img)\n",
    "    output = margin(raw_logits, label)\n",
    "    loss = criterion(output, label)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize and return a dict such that key: layer index, values: filter index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [0, 1, 10, 33, 38, 42, 55],\n",
       " 26: [189],\n",
       " 20: [45, 76],\n",
       " 35: [45, 118],\n",
       " 38: [148],\n",
       " 29: [63, 166, 220],\n",
       " 32: [8],\n",
       " 23: [133, 201],\n",
       " 44: [133]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from operator import itemgetter\n",
    "from heapq import nsmallest\n",
    "prunner.normalize_ranks_per_layer()\n",
    "filters_to_prune = prunner.get_prunning_plan(20)\n",
    "filters_to_prune"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
